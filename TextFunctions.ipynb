{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "845a0a74",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-22T23:12:04.619119Z",
     "start_time": "2023-04-22T23:12:03.364102Z"
    }
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import re\n",
    "import nltk\n",
    "import gensim\n",
    "from nltk.stem import SnowballStemmer   \n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99f41135",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-22T23:12:04.634450Z",
     "start_time": "2023-04-22T23:12:04.619119Z"
    }
   },
   "outputs": [],
   "source": [
    "# Function to get text in selective lowercase form\n",
    "\n",
    "def abbr_or_lower(word):\n",
    "    if re.match('([A-Z]+[a-z]*){2,}', word):\n",
    "        return word\n",
    "    else:\n",
    "        return word.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17f617db",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-22T23:12:04.651379Z",
     "start_time": "2023-04-22T23:12:04.636086Z"
    }
   },
   "outputs": [],
   "source": [
    "# Function for different forms of tokeniztion\n",
    "\n",
    "def tokenize(words, modulation, lowercase='basic'):\n",
    "    tokens = re.split(r'\\W+', words)\n",
    "    stems = []\n",
    "    \n",
    "    # Get comprehensive set of stopwords\n",
    "    stop_words = STOPWORDS.union(set(stopwords.words('english'))) \n",
    "    \n",
    "    # filter out any tokens not containing letters (e.g., numeric tokens, raw punctuation)\n",
    "    for token in tokens:\n",
    "        \n",
    "        # All text as lowercase\n",
    "        if lowercase == 'basic':\n",
    "            lowers = abbr_or_lower(token).lower()\n",
    "        # Custom lowercase to allow all caps text for emphasis\n",
    "        else:\n",
    "            lowers = abbr_or_lower(token)\n",
    "            \n",
    "        if lowers not in stop_words:\n",
    "            if re.search('[a-zA-Z]', lowers):\n",
    "                \n",
    "                # Lowercase \n",
    "                if modulation == 0:\n",
    "                    stems.append(lowers)\n",
    "                    \n",
    "                # Stemming\n",
    "                if modulation == 1:\n",
    "                    porter = SnowballStemmer(\"english\")\n",
    "                    stems.append(porter.stem(lowers))\n",
    "                    \n",
    "                # Lemmatizing\n",
    "                if modulation == 2:\n",
    "                    lmtzr = WordNetLemmatizer()\n",
    "                    stems.append(lmtzr.lemmatize(lowers))\n",
    "                \n",
    "    return stems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b444705e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-22T23:12:04.665818Z",
     "start_time": "2023-04-22T23:12:04.654331Z"
    }
   },
   "outputs": [],
   "source": [
    "# Function to get list of unique words in text\n",
    "\n",
    "def unique_str(list_of_strings):\n",
    "    res = ()\n",
    "    for item in list_of_strings:\n",
    "        res = list(set(res) | set(item))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe1aa8ab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-22T23:12:04.681816Z",
     "start_time": "2023-04-22T23:12:04.665818Z"
    }
   },
   "outputs": [],
   "source": [
    "# Function to get features using key words\n",
    "\n",
    "def get_feature(scraped_text, feature_list):\n",
    "    \n",
    "    empty_list = []\n",
    "    \n",
    "    # Loop through features to check for outdoor spaces\n",
    "    for i in scraped_text:\n",
    "        if len(set(i).intersection(feature_list)) == 0:\n",
    "            empty_list.append(0)\n",
    "        else:\n",
    "            empty_list.append(1)\n",
    "            \n",
    "    return empty_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e05573c4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-22T23:12:04.697554Z",
     "start_time": "2023-04-22T23:12:04.682253Z"
    }
   },
   "outputs": [],
   "source": [
    "# Function to find common words\n",
    "\n",
    "# text = cleaned text format of multiple corpora\n",
    "# hint = text to look for, string\n",
    "# method = text starting with hint, ends with hint, or hint in text\n",
    "\n",
    "def find_words(text, hint, method):\n",
    "    keywords = []\n",
    "    for i in text:\n",
    "        for j in i:\n",
    "            if method == 'startswith':\n",
    "                if j.startswith((hint)) == True:\n",
    "                    keywords.append(j)\n",
    "            if method == 'endswith':\n",
    "                if j.endswith((hint)) == True:\n",
    "                    keywords.append(j)\n",
    "            if method == 'in':\n",
    "                if hint in j:\n",
    "                    keywords.append(j)\n",
    "    return set(keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6896d5e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
